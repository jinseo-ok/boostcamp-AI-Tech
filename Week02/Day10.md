# Week02 - AI Math

## [Day 10] - 시각화 도구 / 통계학 맛보기

### 1. 시각화 도구

데이터 분석을 위한 방법 중 하나로 데이터 시각화가 있다.

기존 데이터를 시각화함으로써 데이터 자체에서 볼 수 없었던 특징과 인사이트를 추론할 수 있고 처리된 데이터 혹은 모델 결과를 시각화함으로써 보다 전달력있는 자료를 만들 수 있다.
시각화는 데이터 분석을 위한 가장 기초적인 단계로 python에서는 다양한 라이브러리가 존재한다. 그 중에서 가장 대중적으로 많이 쓰이는 matplotlib, seaborn 모듈에 대해 학습할 필요가 있다.

#### 1) **matplotlib**

가장 대중적으로 많이 쓰였고 많은 python 라이브러리의 근간이 되는 라이브러리이다. matplotlib는 다른 라이브러리들의 부모 라이브러리로서의 역할을 하고 있다고 표현할정도로 다른 라이브러리들에 많은 영향을 주었다. 다소 복잡한 라이브러리 구성으로 인해 최근에는 그 사용 빈도와 대중성이 떨어지고 있으나 여전히 많은 입문자들이 처음 사용해보게 되는 좋은 시각화 라이브러리이다. 특히 R의 ggplot 라이브러리와 굉장히 유사한 면이 있다.

  - pyplot 객체를 사용하여 데이터를 펴ㅛ시
  - pyplot 객체에 그래프들을 쌓은 다음 flush(메모리에 저장 후 반환) `plt.show()`
  - 고정된 argument가 없어서 argument에 대한 정보를 확인하기 어려움
  - Graph는 원래 figure 객체에 생성됨
  - pyplot 객체 사용 시, 기본 figure에 그래프가 그려짐

##### (1) Figure & Axes

  - MAtplotlib은 Figure 안에 Axes로 구성
  - Figure 위에 여러 개의 Axes를 생성

<image src = https://user-images.githubusercontent.com/48677363/106230079-124f3600-6232-11eb-8db4-f2c476974319.png width = 300>




##### (2) color

  - [matplotlib color 문서](https://matplotlib.org/3.1.0/gallery/color/named_colors.html)

  - [RGB 코드](https://www.rapidtables.com/web/color/RGB_Color.html)

**seaborn**

시각화를 위한 다양한 기능을 손쉽게 사용할 수 있도록 지원합니다. 모든 기능은 matplotlib을 기반으로 제공되어 matplotlib과 상호 호환됩니다. matplotlib의 모든 기능을 사용하면서 손 쉽게 사용하고 싶다면 seaborn이 가장 적절한 대안입니다.

-----------

### 2. 통계학 맛보기

모수의 개념과 모수를 추정하는 방법으로 최대가능도 추정법이 있다.

정규분포, 카테고리분포에서의 예제로 최대가능도 추정법을 설명합니다.


표본분포와 표집분포, 가능도(likelihood)와 확률 등 헷갈릴 수 있는 개념들이 많이 소개되므로 각각의 정확한 의미와 차이점을 충분히 공부하고 넘어가시기 바랍니다.

최대가능도 추정법을 통해서 정답에 해당하는 확률분포와 모델이 추정하는 확률분포의 거리를 최소화함으로써 모델을 학습시킬 수 있으며, 이 원리는 딥러닝/머신러닝에서 아주 유용하게 사용되기 때문에 확실하게 이해하셨으면 좋겠습니다.


#### 1) 모수

모수는 모집단의 특성(모평균,모분산 등..)을 나타내는 값으로, 이 값은 모집단을 전수조사해야만 알수있는 값이다. 그러나 실질적으로 모집단의 크기와 범위가 너무 방대하기에 전수조사를 실지하지 않고 표본조사를 하는데 표본평균,표본분산 등으로 모평균, 모분산등을 추정할수가 있다.

통계적 모델링은 적절한 가정 위에서 확률분포를 추정(inference)하는 것이 목표이며, 기계학습과 통계학이 공통적으로 추구하는 목표이다.
그러나 표본집단에서 모집단의 분포를 정확히 알아내는 것은 불가능하므로, 근사적으로 확률분포를 추정할 수 밖에 없다.

❗️예측 모형의 목적은 분포를 정확하게 맞추는 것보다는 데이터와 추정 방법의 불확실성을 고려해서 위험을 최소화하는 것이다.
 
  - 모수적 방법론(parametric method): 데이터가 특정 확률분포를 따른다고 선험적으로(a priori) 가정한 후 그 분포를 결정하는 모수(parameter)를 추정하는 방법
  - 비모수 방법론(nonparametric method): 특정 확률분포를 가정하지 않고 데이터에 따라 모델의 구조 및 모수의 개수를 유연하게 바꾸는 방법(기계학습의 많은 방법론은 비모수 방법론에 속함)

#### 2) 확률분포 가정하기

  - 베르누이분포: 데이터가 2개의 값(0, 1)만 가지는 경우
  - 카테고리분포: 데이터가 n개의 이산적인 값을 가지는 경우
  - 베타분포: 데이터가 [0, 1] 사이에서 값을 가지는 경우
  - 감마분포, 로그정규분포 등: 데이터가 0이상의 값을 가지는 경우
  - 정규분포, 라플라스분포 등: 데이터가 R 전체에서 값을 가지는 경우

**기계적으로 확률분포를 가정해서는 안되며, 데이터를 생성하는 원리는 먼저 고려하는 것이 원칙이다.**

#### 3) 모수 추정하기

확률분포를 가정했다면 모수를 추정해볼 수 있다. 통계량의 확률분포를 표집분포(sampling distribution)라 부르며, 특히 표번평균의 포집분포는 N이 커질수록 정규분포 $𝒩(μ, σ2/N)$를 따른다.

❗️ 중심극한정리란 표본평균의 표집분포는 N이 커질수록(최대한 많이 조사할수록.., 최대한 많은 데이터를 확보할수록) 정규분포에 근사함을 의미한다.

#### 3) 최대가능도 추정법

표본평균, 표본분산은 중요한 통계량이지만 확률분포마다 사용하는 모수(parameter)가 다르므로 적절한 통계량이 달라지게 된다. 그러므로 표본평균과 표본분산만 가지고 확률분포를 추정하는 것은 위험하다.

이론적으로 가장 가능성이 높은 모수를 추정하는 방법 중 하나는 **최대가능 추정법(Maximum Likelihood Extimation, MLE)** 이다.

<image src = https://user-images.githubusercontent.com/48677363/106244184-e6da4480-624d-11eb-9d59-38794767063f.png width = 350>

❗️likelihood는 모수 $θ$ 를 따르는 분포가 $x$ 를 관찰할 가능성을 뜻하지만 확률로 해석하면 안된다.

이 때, 데이터 집합 X (확률변수?)가 독립적으로 추출되었을 경우, 로그가능도를 최적화한다.

사실 로그가능도를 최적화하는 모수와 기본 가능도를 최적화하는 모수는 똑같이 MLE를 의미한다. 그럼에도 불구하고 로그가능도를 최적화하는 이유는 computation 문제에 있다.
데이터가 수억단위의 크기가 될 때에는 컴퓨터의 정확도로 가능도를 계산하는 것은 불가능하다. 하지만 로그가능도를 사용하게 되면 곱셈이 덧셈으로 치환되기 때문에 연산이 가능해지고 최적화가 가능해진다.

추가적으로 경사하강법으로 가능도를 최적화할 때, 미분 연산을 사용하게 되는데 로그가능도를 사용하면 연산량을 $O(n2)$ 에서 $O(n)$으로 줄여준다. 대부분의 손실함수의 경우, 경사하강법이 적용되므로 음의 로그가능도(negative log-likelihood)를 최적화하게 된다.

 
