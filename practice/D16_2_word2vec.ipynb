{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"2_word2vec.ipynb의 사본","provenance":[{"file_id":"1VTvW_xhCVskuAJokXST6RImd8CAZ7Pdr","timestamp":1613384667670}],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"h3FAK0fz1kOr"},"source":["##**2. Word2Vec**\r\n","1. 주어진 단어들을 word2vec 모델에 들어갈 수 있는 형태로 만듭니다.\r\n","2. CBOW, Skip-gram 모델을 각각 구현합니다.\r\n","3. 모델을 실제로 학습해보고 결과를 확인합니다."]},{"cell_type":"markdown","metadata":{"id":"u9FrxTPWIsct"},"source":["### **필요 패키지 import**"]},{"cell_type":"code","metadata":{"id":"QjroCdtwI9Rz","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1613384703841,"user_tz":-540,"elapsed":7988,"user":{"displayName":"오진석","photoUrl":"","userId":"12229120938967938448"}},"outputId":"76d6dc81-476b-46ec-b390-f876c3a6b89b"},"source":["!pip install konlpy"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Collecting konlpy\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/85/0e/f385566fec837c0b83f216b2da65db9997b35dd675e107752005b7d392b1/konlpy-0.5.2-py2.py3-none-any.whl (19.4MB)\n","\u001b[K     |████████████████████████████████| 19.4MB 53.4MB/s \n","\u001b[?25hRequirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.6/dist-packages (from konlpy) (4.2.6)\n","Collecting JPype1>=0.7.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/af/93f92b38ec1ff3091cd38982ed19cea2800fefb609b5801c41fc43c0781e/JPype1-1.2.1-cp36-cp36m-manylinux2010_x86_64.whl (457kB)\n","\u001b[K     |████████████████████████████████| 460kB 31.9MB/s \n","\u001b[?25hCollecting tweepy>=3.7.0\n","  Downloading https://files.pythonhosted.org/packages/67/c3/6bed87f3b1e5ed2f34bd58bf7978e308c86e255193916be76e5a5ce5dfca/tweepy-3.10.0-py2.py3-none-any.whl\n","Collecting beautifulsoup4==4.6.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/d4/10f46e5cfac773e22707237bfcd51bbffeaf0a576b0a847ec7ab15bd7ace/beautifulsoup4-4.6.0-py3-none-any.whl (86kB)\n","\u001b[K     |████████████████████████████████| 92kB 8.4MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.6/dist-packages (from konlpy) (1.19.5)\n","Collecting colorama\n","  Downloading https://files.pythonhosted.org/packages/44/98/5b86278fbbf250d239ae0ecb724f8572af1c91f4a11edf4d36a206189440/colorama-0.4.4-py2.py3-none-any.whl\n","Requirement already satisfied: typing-extensions; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from JPype1>=0.7.0->konlpy) (3.7.4.3)\n","Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (1.15.0)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (1.3.0)\n","Requirement already satisfied: requests[socks]>=2.11.1 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (2.23.0)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->tweepy>=3.7.0->konlpy) (3.1.0)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2020.12.5)\n","Requirement already satisfied: PySocks!=1.5.7,>=1.5.6; extra == \"socks\" in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.7.1)\n","Installing collected packages: JPype1, tweepy, beautifulsoup4, colorama, konlpy\n","  Found existing installation: tweepy 3.6.0\n","    Uninstalling tweepy-3.6.0:\n","      Successfully uninstalled tweepy-3.6.0\n","  Found existing installation: beautifulsoup4 4.6.3\n","    Uninstalling beautifulsoup4-4.6.3:\n","      Successfully uninstalled beautifulsoup4-4.6.3\n","Successfully installed JPype1-1.2.1 beautifulsoup4-4.6.0 colorama-0.4.4 konlpy-0.5.2 tweepy-3.10.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"nSP7aXfJIr3i","executionInfo":{"status":"ok","timestamp":1613384708415,"user_tz":-540,"elapsed":12557,"user":{"displayName":"오진석","photoUrl":"","userId":"12229120938967938448"}}},"source":["from tqdm import tqdm\r\n","from konlpy.tag import Okt\r\n","from torch import nn\r\n","from torch.nn import functional as F\r\n","from torch.utils.data import Dataset, DataLoader\r\n","from collections import defaultdict\r\n","\r\n","import torch\r\n","import copy\r\n","import numpy as np"],"execution_count":2,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qugro74yJASr"},"source":["### **데이터 전처리**"]},{"cell_type":"markdown","metadata":{"id":"Q36dfSRRJDtX"},"source":["\r\n","\r\n","데이터를 확인하고 Word2Vec 형식에 맞게 전처리합니다.  \r\n","학습 데이터는 1번 실습과 동일하고, 테스트를 위한 단어를 아래와 같이 가정해봅시다."]},{"cell_type":"code","metadata":{"id":"CLZ2f-lRJSus","executionInfo":{"status":"ok","timestamp":1613384708416,"user_tz":-540,"elapsed":12555,"user":{"displayName":"오진석","photoUrl":"","userId":"12229120938967938448"}}},"source":["train_data = [\r\n","  \"정말 맛있습니다. 추천합니다.\",\r\n","  \"기대했던 것보단 별로였네요.\",\r\n","  \"다 좋은데 가격이 너무 비싸서 다시 가고 싶다는 생각이 안 드네요.\",\r\n","  \"완전 최고입니다! 재방문 의사 있습니다.\",\r\n","  \"음식도 서비스도 다 만족스러웠습니다.\",\r\n","  \"위생 상태가 좀 별로였습니다. 좀 더 개선되기를 바랍니다.\",\r\n","  \"맛도 좋았고 직원분들 서비스도 너무 친절했습니다.\",\r\n","  \"기념일에 방문했는데 음식도 분위기도 서비스도 다 좋았습니다.\",\r\n","  \"전반적으로 음식이 너무 짰습니다. 저는 별로였네요.\",\r\n","  \"위생에 조금 더 신경 썼으면 좋겠습니다. 조금 불쾌했습니다.\"       \r\n","]\r\n","\r\n","test_words = [\"음식\", \"맛\", \"서비스\", \"위생\", \"가격\"] # -> 학습된 Word2Vec 모델로 test word의 벡터를 뽑아내는 것"],"execution_count":3,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vReElaFSLBYL"},"source":["Tokenization과 vocab을 만드는 과정은 이전 실습과 유사합니다."]},{"cell_type":"code","metadata":{"id":"dTjlRzmWMDK_","executionInfo":{"status":"ok","timestamp":1613384709961,"user_tz":-540,"elapsed":14098,"user":{"displayName":"오진석","photoUrl":"","userId":"12229120938967938448"}}},"source":["tokenizer = Okt()"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"0DTUsX672icp","executionInfo":{"status":"ok","timestamp":1613384709962,"user_tz":-540,"elapsed":14096,"user":{"displayName":"오진석","photoUrl":"","userId":"12229120938967938448"}}},"source":["# 토크나이징\r\n","def make_tokenized(data):\r\n","  tokenized = []\r\n","  for sent in tqdm(data):\r\n","    tokens = tokenizer.morphs(sent, stem=True)\r\n","    tokenized.append(tokens)\r\n","\r\n","  return tokenized"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"C-z0z6HD2rrX","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1613384715782,"user_tz":-540,"elapsed":19909,"user":{"displayName":"오진석","photoUrl":"","userId":"12229120938967938448"}},"outputId":"f8399abe-cf56-4ab2-83e1-953e19282277"},"source":["train_tokenized = make_tokenized(train_data)"],"execution_count":6,"outputs":[{"output_type":"stream","text":["100%|██████████| 10/10 [00:06<00:00,  1.59it/s]\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mlYGZ9wAPdjG","executionInfo":{"status":"ok","timestamp":1613385107379,"user_tz":-540,"elapsed":1031,"user":{"displayName":"오진석","photoUrl":"","userId":"12229120938967938448"}},"outputId":"39c6c389-01d6-4a4a-8299-eaed01055bb8"},"source":["train_tokenized[:4]"],"execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[['정말', '맛있다', '.', '추천', '하다', '.'],\n"," ['기대하다', '것', '보단', '별로', '이다', '.'],\n"," ['다',\n","  '좋다',\n","  '가격',\n","  '이',\n","  '너무',\n","  '비싸다',\n","  '다시',\n","  '가다',\n","  '싶다',\n","  '생각',\n","  '이',\n","  '안',\n","  '드네',\n","  '요',\n","  '.'],\n"," ['완전', '최고', '이다', '!', '재', '방문', '의사', '있다', '.']]"]},"metadata":{"tags":[]},"execution_count":14}]},{"cell_type":"code","metadata":{"id":"51exEpI0Mc3l","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1613384715783,"user_tz":-540,"elapsed":19687,"user":{"displayName":"오진석","photoUrl":"","userId":"12229120938967938448"}},"outputId":"c70a533b-f6fe-4eff-b2d1-4a1d71ded924"},"source":["word_count = defaultdict(int)\r\n","\r\n","for tokens in tqdm(train_tokenized):\r\n","  for token in tokens:\r\n","    word_count[token] += 1"],"execution_count":7,"outputs":[{"output_type":"stream","text":["100%|██████████| 10/10 [00:00<00:00, 3840.59it/s]\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"gyvHAMAnMh1D","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1613384855751,"user_tz":-540,"elapsed":1305,"user":{"displayName":"오진석","photoUrl":"","userId":"12229120938967938448"}},"outputId":"de540dd8-7291-4f38-a910-28c40e2deccc"},"source":["word_count = sorted(word_count.items(), key=lambda x: x[1], reverse=True)\r\n","print(list(word_count))"],"execution_count":8,"outputs":[{"output_type":"stream","text":["[('.', 14), ('도', 7), ('이다', 4), ('좋다', 4), ('별로', 3), ('다', 3), ('이', 3), ('너무', 3), ('음식', 3), ('서비스', 3), ('하다', 2), ('방문', 2), ('위생', 2), ('좀', 2), ('더', 2), ('에', 2), ('조금', 2), ('정말', 1), ('맛있다', 1), ('추천', 1), ('기대하다', 1), ('것', 1), ('보단', 1), ('가격', 1), ('비싸다', 1), ('다시', 1), ('가다', 1), ('싶다', 1), ('생각', 1), ('안', 1), ('드네', 1), ('요', 1), ('완전', 1), ('최고', 1), ('!', 1), ('재', 1), ('의사', 1), ('있다', 1), ('만족스럽다', 1), ('상태', 1), ('가', 1), ('개선', 1), ('되다', 1), ('기르다', 1), ('바라다', 1), ('맛', 1), ('직원', 1), ('분들', 1), ('친절하다', 1), ('기념일', 1), ('분위기', 1), ('전반', 1), ('적', 1), ('으로', 1), ('짜다', 1), ('저', 1), ('는', 1), ('신경', 1), ('써다', 1), ('불쾌하다', 1)]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"DaK_i3zL2vO3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1613384856872,"user_tz":-540,"elapsed":1208,"user":{"displayName":"오진석","photoUrl":"","userId":"12229120938967938448"}},"outputId":"185810fd-88b9-4e26-bda8-5f27b3907849"},"source":["w2i = {}\r\n","for pair in tqdm(word_count):\r\n","  if pair[0] not in w2i:\r\n","    w2i[pair[0]] = len(w2i)"],"execution_count":9,"outputs":[{"output_type":"stream","text":["100%|██████████| 60/60 [00:00<00:00, 109607.25it/s]\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"LiGqiEGDL5B_","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1613384858865,"user_tz":-540,"elapsed":1294,"user":{"displayName":"오진석","photoUrl":"","userId":"12229120938967938448"}},"outputId":"0efc9785-06d7-43bb-8c3c-d231fa2ccccf"},"source":["print(train_tokenized)\r\n","print(w2i)"],"execution_count":10,"outputs":[{"output_type":"stream","text":["[['정말', '맛있다', '.', '추천', '하다', '.'], ['기대하다', '것', '보단', '별로', '이다', '.'], ['다', '좋다', '가격', '이', '너무', '비싸다', '다시', '가다', '싶다', '생각', '이', '안', '드네', '요', '.'], ['완전', '최고', '이다', '!', '재', '방문', '의사', '있다', '.'], ['음식', '도', '서비스', '도', '다', '만족스럽다', '.'], ['위생', '상태', '가', '좀', '별로', '이다', '.', '좀', '더', '개선', '되다', '기르다', '바라다', '.'], ['맛', '도', '좋다', '직원', '분들', '서비스', '도', '너무', '친절하다', '.'], ['기념일', '에', '방문', '하다', '음식', '도', '분위기', '도', '서비스', '도', '다', '좋다', '.'], ['전반', '적', '으로', '음식', '이', '너무', '짜다', '.', '저', '는', '별로', '이다', '.'], ['위생', '에', '조금', '더', '신경', '써다', '좋다', '.', '조금', '불쾌하다', '.']]\n","{'.': 0, '도': 1, '이다': 2, '좋다': 3, '별로': 4, '다': 5, '이': 6, '너무': 7, '음식': 8, '서비스': 9, '하다': 10, '방문': 11, '위생': 12, '좀': 13, '더': 14, '에': 15, '조금': 16, '정말': 17, '맛있다': 18, '추천': 19, '기대하다': 20, '것': 21, '보단': 22, '가격': 23, '비싸다': 24, '다시': 25, '가다': 26, '싶다': 27, '생각': 28, '안': 29, '드네': 30, '요': 31, '완전': 32, '최고': 33, '!': 34, '재': 35, '의사': 36, '있다': 37, '만족스럽다': 38, '상태': 39, '가': 40, '개선': 41, '되다': 42, '기르다': 43, '바라다': 44, '맛': 45, '직원': 46, '분들': 47, '친절하다': 48, '기념일': 49, '분위기': 50, '전반': 51, '적': 52, '으로': 53, '짜다': 54, '저': 55, '는': 56, '신경': 57, '써다': 58, '불쾌하다': 59}\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"vXA5zaPPM3Wd"},"source":["실제 모델에 들어가기 위한 input을 만들기 위해 `Dataset` 클래스를 정의합니다."]},{"cell_type":"code","metadata":{"id":"s47ssyVt89t1","executionInfo":{"status":"ok","timestamp":1613384954813,"user_tz":-540,"elapsed":1375,"user":{"displayName":"오진석","photoUrl":"","userId":"12229120938967938448"}}},"source":["class CBOWDataset(Dataset):\r\n","  def __init__(self, train_tokenized, window_size=2):\r\n","    self.x = []\r\n","    self.y = []\r\n","\r\n","    for tokens in tqdm(train_tokenized):\r\n","      token_ids = [w2i[token] for token in tokens]\r\n","      for i, id in enumerate(token_ids):\r\n","        if i-window_size >= 0 and i+window_size < len(token_ids):\r\n","          self.x.append(token_ids[i-window_size:i] + token_ids[i+1:i+window_size+1])\r\n","          self.y.append(id)\r\n","\r\n","    self.x = torch.LongTensor(self.x)  # (전체 데이터 개수, 2 * window_size)\r\n","    self.y = torch.LongTensor(self.y)  # (전체 데이터 개수)\r\n","\r\n","  def __len__(self):\r\n","    return self.x.shape[0]\r\n","\r\n","  def __getitem__(self, idx):\r\n","    return self.x[idx], self.y[idx]"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"kvInhQ33AMJv","executionInfo":{"status":"ok","timestamp":1613384955996,"user_tz":-540,"elapsed":1310,"user":{"displayName":"오진석","photoUrl":"","userId":"12229120938967938448"}}},"source":["class SkipGramDataset(Dataset):\r\n","  def __init__(self, train_tokenized, window_size=2):\r\n","    self.x = []\r\n","    self.y = []\r\n","\r\n","    for tokens in tqdm(train_tokenized):\r\n","      token_ids = [w2i[token] for token in tokens]\r\n","      for i, id in enumerate(token_ids):\r\n","        if i-window_size >= 0 and i+window_size < len(token_ids):\r\n","          self.y += (token_ids[i-window_size:i] + token_ids[i+1:i+window_size+1])\r\n","          self.x += [id] * 2 * window_size\r\n","\r\n","    self.x = torch.LongTensor(self.x)  # (전체 데이터 개수)\r\n","    self.y = torch.LongTensor(self.y)  # (전체 데이터 개수)\r\n","\r\n","  def __len__(self):\r\n","    return self.x.shape[0]\r\n","\r\n","  def __getitem__(self, idx):\r\n","    return self.x[idx], self.y[idx]"],"execution_count":12,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JyAGV5IUUba0"},"source":["각 모델에 맞는 `Dataset` 객체를 생성합니다."]},{"cell_type":"code","metadata":{"id":"5ep7Hm6oBWyy","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1613385349704,"user_tz":-540,"elapsed":1233,"user":{"displayName":"오진석","photoUrl":"","userId":"12229120938967938448"}},"outputId":"fa484659-b733-459c-e3da-1d8a275c927d"},"source":["cbow_set = CBOWDataset(train_tokenized)\r\n","skipgram_set = SkipGramDataset(train_tokenized)\r\n","print(list(skipgram_set))"],"execution_count":19,"outputs":[{"output_type":"stream","text":["100%|██████████| 10/10 [00:00<00:00, 12271.22it/s]\n","100%|██████████| 10/10 [00:00<00:00, 1241.43it/s]"],"name":"stderr"},{"output_type":"stream","text":["[(tensor(0), tensor(17)), (tensor(0), tensor(18)), (tensor(0), tensor(19)), (tensor(0), tensor(10)), (tensor(19), tensor(18)), (tensor(19), tensor(0)), (tensor(19), tensor(10)), (tensor(19), tensor(0)), (tensor(22), tensor(20)), (tensor(22), tensor(21)), (tensor(22), tensor(4)), (tensor(22), tensor(2)), (tensor(4), tensor(21)), (tensor(4), tensor(22)), (tensor(4), tensor(2)), (tensor(4), tensor(0)), (tensor(23), tensor(5)), (tensor(23), tensor(3)), (tensor(23), tensor(6)), (tensor(23), tensor(7)), (tensor(6), tensor(3)), (tensor(6), tensor(23)), (tensor(6), tensor(7)), (tensor(6), tensor(24)), (tensor(7), tensor(23)), (tensor(7), tensor(6)), (tensor(7), tensor(24)), (tensor(7), tensor(25)), (tensor(24), tensor(6)), (tensor(24), tensor(7)), (tensor(24), tensor(25)), (tensor(24), tensor(26)), (tensor(25), tensor(7)), (tensor(25), tensor(24)), (tensor(25), tensor(26)), (tensor(25), tensor(27)), (tensor(26), tensor(24)), (tensor(26), tensor(25)), (tensor(26), tensor(27)), (tensor(26), tensor(28)), (tensor(27), tensor(25)), (tensor(27), tensor(26)), (tensor(27), tensor(28)), (tensor(27), tensor(6)), (tensor(28), tensor(26)), (tensor(28), tensor(27)), (tensor(28), tensor(6)), (tensor(28), tensor(29)), (tensor(6), tensor(27)), (tensor(6), tensor(28)), (tensor(6), tensor(29)), (tensor(6), tensor(30)), (tensor(29), tensor(28)), (tensor(29), tensor(6)), (tensor(29), tensor(30)), (tensor(29), tensor(31)), (tensor(30), tensor(6)), (tensor(30), tensor(29)), (tensor(30), tensor(31)), (tensor(30), tensor(0)), (tensor(2), tensor(32)), (tensor(2), tensor(33)), (tensor(2), tensor(34)), (tensor(2), tensor(35)), (tensor(34), tensor(33)), (tensor(34), tensor(2)), (tensor(34), tensor(35)), (tensor(34), tensor(11)), (tensor(35), tensor(2)), (tensor(35), tensor(34)), (tensor(35), tensor(11)), (tensor(35), tensor(36)), (tensor(11), tensor(34)), (tensor(11), tensor(35)), (tensor(11), tensor(36)), (tensor(11), tensor(37)), (tensor(36), tensor(35)), (tensor(36), tensor(11)), (tensor(36), tensor(37)), (tensor(36), tensor(0)), (tensor(9), tensor(8)), (tensor(9), tensor(1)), (tensor(9), tensor(1)), (tensor(9), tensor(5)), (tensor(1), tensor(1)), (tensor(1), tensor(9)), (tensor(1), tensor(5)), (tensor(1), tensor(38)), (tensor(5), tensor(9)), (tensor(5), tensor(1)), (tensor(5), tensor(38)), (tensor(5), tensor(0)), (tensor(40), tensor(12)), (tensor(40), tensor(39)), (tensor(40), tensor(13)), (tensor(40), tensor(4)), (tensor(13), tensor(39)), (tensor(13), tensor(40)), (tensor(13), tensor(4)), (tensor(13), tensor(2)), (tensor(4), tensor(40)), (tensor(4), tensor(13)), (tensor(4), tensor(2)), (tensor(4), tensor(0)), (tensor(2), tensor(13)), (tensor(2), tensor(4)), (tensor(2), tensor(0)), (tensor(2), tensor(13)), (tensor(0), tensor(4)), (tensor(0), tensor(2)), (tensor(0), tensor(13)), (tensor(0), tensor(14)), (tensor(13), tensor(2)), (tensor(13), tensor(0)), (tensor(13), tensor(14)), (tensor(13), tensor(41)), (tensor(14), tensor(0)), (tensor(14), tensor(13)), (tensor(14), tensor(41)), (tensor(14), tensor(42)), (tensor(41), tensor(13)), (tensor(41), tensor(14)), (tensor(41), tensor(42)), (tensor(41), tensor(43)), (tensor(42), tensor(14)), (tensor(42), tensor(41)), (tensor(42), tensor(43)), (tensor(42), tensor(44)), (tensor(43), tensor(41)), (tensor(43), tensor(42)), (tensor(43), tensor(44)), (tensor(43), tensor(0)), (tensor(3), tensor(45)), (tensor(3), tensor(1)), (tensor(3), tensor(46)), (tensor(3), tensor(47)), (tensor(46), tensor(1)), (tensor(46), tensor(3)), (tensor(46), tensor(47)), (tensor(46), tensor(9)), (tensor(47), tensor(3)), (tensor(47), tensor(46)), (tensor(47), tensor(9)), (tensor(47), tensor(1)), (tensor(9), tensor(46)), (tensor(9), tensor(47)), (tensor(9), tensor(1)), (tensor(9), tensor(7)), (tensor(1), tensor(47)), (tensor(1), tensor(9)), (tensor(1), tensor(7)), (tensor(1), tensor(48)), (tensor(7), tensor(9)), (tensor(7), tensor(1)), (tensor(7), tensor(48)), (tensor(7), tensor(0)), (tensor(11), tensor(49)), (tensor(11), tensor(15)), (tensor(11), tensor(10)), (tensor(11), tensor(8)), (tensor(10), tensor(15)), (tensor(10), tensor(11)), (tensor(10), tensor(8)), (tensor(10), tensor(1)), (tensor(8), tensor(11)), (tensor(8), tensor(10)), (tensor(8), tensor(1)), (tensor(8), tensor(50)), (tensor(1), tensor(10)), (tensor(1), tensor(8)), (tensor(1), tensor(50)), (tensor(1), tensor(1)), (tensor(50), tensor(8)), (tensor(50), tensor(1)), (tensor(50), tensor(1)), (tensor(50), tensor(9)), (tensor(1), tensor(1)), (tensor(1), tensor(50)), (tensor(1), tensor(9)), (tensor(1), tensor(1)), (tensor(9), tensor(50)), (tensor(9), tensor(1)), (tensor(9), tensor(1)), (tensor(9), tensor(5)), (tensor(1), tensor(1)), (tensor(1), tensor(9)), (tensor(1), tensor(5)), (tensor(1), tensor(3)), (tensor(5), tensor(9)), (tensor(5), tensor(1)), (tensor(5), tensor(3)), (tensor(5), tensor(0)), (tensor(53), tensor(51)), (tensor(53), tensor(52)), (tensor(53), tensor(8)), (tensor(53), tensor(6)), (tensor(8), tensor(52)), (tensor(8), tensor(53)), (tensor(8), tensor(6)), (tensor(8), tensor(7)), (tensor(6), tensor(53)), (tensor(6), tensor(8)), (tensor(6), tensor(7)), (tensor(6), tensor(54)), (tensor(7), tensor(8)), (tensor(7), tensor(6)), (tensor(7), tensor(54)), (tensor(7), tensor(0)), (tensor(54), tensor(6)), (tensor(54), tensor(7)), (tensor(54), tensor(0)), (tensor(54), tensor(55)), (tensor(0), tensor(7)), (tensor(0), tensor(54)), (tensor(0), tensor(55)), (tensor(0), tensor(56)), (tensor(55), tensor(54)), (tensor(55), tensor(0)), (tensor(55), tensor(56)), (tensor(55), tensor(4)), (tensor(56), tensor(0)), (tensor(56), tensor(55)), (tensor(56), tensor(4)), (tensor(56), tensor(2)), (tensor(4), tensor(55)), (tensor(4), tensor(56)), (tensor(4), tensor(2)), (tensor(4), tensor(0)), (tensor(16), tensor(12)), (tensor(16), tensor(15)), (tensor(16), tensor(14)), (tensor(16), tensor(57)), (tensor(14), tensor(15)), (tensor(14), tensor(16)), (tensor(14), tensor(57)), (tensor(14), tensor(58)), (tensor(57), tensor(16)), (tensor(57), tensor(14)), (tensor(57), tensor(58)), (tensor(57), tensor(3)), (tensor(58), tensor(14)), (tensor(58), tensor(57)), (tensor(58), tensor(3)), (tensor(58), tensor(0)), (tensor(3), tensor(57)), (tensor(3), tensor(58)), (tensor(3), tensor(0)), (tensor(3), tensor(16)), (tensor(0), tensor(58)), (tensor(0), tensor(3)), (tensor(0), tensor(16)), (tensor(0), tensor(59)), (tensor(16), tensor(3)), (tensor(16), tensor(0)), (tensor(16), tensor(59)), (tensor(16), tensor(0))]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"1QSo73PoRyd9"},"source":["### **모델 Class 구현**"]},{"cell_type":"markdown","metadata":{"id":"jnnk44R6R28x"},"source":["차례대로 두 가지 Word2Vec 모델을 구현합니다.  \r\n","\r\n","\r\n","*   `self.embedding`: `vocab_size` 크기의 one-hot vector를 특정 크기의 `dim` 차원으로 embedding 시키는 layer.\r\n","*   `self.linear`: 변환된 embedding vector를 다시 원래 `vocab_size`로 바꾸는 layer.\r\n"]},{"cell_type":"code","metadata":{"id":"b_HP1ISq5CWv","executionInfo":{"status":"ok","timestamp":1613385330904,"user_tz":-540,"elapsed":1461,"user":{"displayName":"오진석","photoUrl":"","userId":"12229120938967938448"}}},"source":["class CBOW(nn.Module):\r\n","  def __init__(self, vocab_size, dim):\r\n","    super(CBOW, self).__init__()\r\n","    self.embedding = nn.Embedding(vocab_size, dim, sparse=True)\r\n","    self.linear = nn.Linear(dim, vocab_size)\r\n","\r\n","  # B: batch size, W: window size, d_w: word embedding size, V: vocab size\r\n","  def forward(self, x):  # x: (B, 2W)\r\n","    embeddings = self.embedding(x)  # (B, 2W, d_w)\r\n","    embeddings = torch.sum(embeddings, dim=1)  # (B, d_w)\r\n","    output = self.linear(embeddings)  # (B, V)\r\n","    return output"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"id":"yQAUApww68MJ","executionInfo":{"status":"ok","timestamp":1613385330904,"user_tz":-540,"elapsed":1214,"user":{"displayName":"오진석","photoUrl":"","userId":"12229120938967938448"}}},"source":["class SkipGram(nn.Module):\r\n","  def __init__(self, vocab_size, dim):\r\n","    super(SkipGram, self).__init__()\r\n","    self.embedding = nn.Embedding(vocab_size, dim, sparse=True)\r\n","    self.linear = nn.Linear(dim, vocab_size)\r\n","\r\n","  # B: batch size, W: window size, d_w: word embedding size, V: vocab size\r\n","  def forward(self, x): # x: (B)\r\n","    embeddings = self.embedding(x)  # (B, d_w)\r\n","    output = self.linear(embeddings)  # (B, V)\r\n","    return output"],"execution_count":16,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"58cJalkDWYMT"},"source":["두 가지 모델을 생성합니다."]},{"cell_type":"code","metadata":{"id":"8vWUXEi8WeM-","executionInfo":{"status":"ok","timestamp":1613385332405,"user_tz":-540,"elapsed":1107,"user":{"displayName":"오진석","photoUrl":"","userId":"12229120938967938448"}}},"source":["cbow = CBOW(vocab_size=len(w2i), dim=256)\r\n","skipgram = SkipGram(vocab_size=len(w2i), dim=256)"],"execution_count":17,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xxP7qdtNWil1"},"source":["### **모델 학습**"]},{"cell_type":"markdown","metadata":{"id":"QVggZrQ4WpBS"},"source":["다음과 같이 hyperparamter를 세팅하고 `DataLoader` 객체를 만듭니다."]},{"cell_type":"code","metadata":{"id":"ygVdz5rSBeNu","executionInfo":{"status":"ok","timestamp":1613385353325,"user_tz":-540,"elapsed":1011,"user":{"displayName":"오진석","photoUrl":"","userId":"12229120938967938448"}}},"source":["batch_size=4\r\n","learning_rate = 5e-4\r\n","num_epochs = 5\r\n","device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\r\n","\r\n","cbow_loader = DataLoader(cbow_set, batch_size=batch_size)\r\n","skipgram_loader = DataLoader(skipgram_set, batch_size=batch_size)"],"execution_count":20,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ekixqKB3X5C1"},"source":["첫번째로 CBOW 모델 학습입니다."]},{"cell_type":"code","metadata":{"id":"-d95qR7oC822","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1613385365874,"user_tz":-540,"elapsed":9721,"user":{"displayName":"오진석","photoUrl":"","userId":"12229120938967938448"}},"outputId":"99e67743-a5df-4e01-fb92-181bfef59529"},"source":["cbow.train()\r\n","cbow = cbow.to(device)\r\n","optim = torch.optim.SGD(cbow.parameters(), lr=learning_rate)\r\n","loss_function = nn.CrossEntropyLoss()\r\n","\r\n","for e in range(1, num_epochs+1):\r\n","  print(\"#\" * 50)\r\n","  print(f\"Epoch: {e}\")\r\n","  for batch in tqdm(cbow_loader):\r\n","    x, y = batch\r\n","    x, y = x.to(device), y.to(device) # (B, W), (B)\r\n","    output = cbow(x)  # (B, V)\r\n"," \r\n","    optim.zero_grad()\r\n","    loss = loss_function(output, y)\r\n","    loss.backward()\r\n","    optim.step()\r\n","\r\n","    print(f\"Train loss: {loss.item()}\")\r\n","\r\n","print(\"Finished.\")"],"execution_count":21,"outputs":[{"output_type":"stream","text":["  6%|▋         | 1/16 [00:00<00:02,  5.61it/s]"],"name":"stderr"},{"output_type":"stream","text":["##################################################\n","Epoch: 1\n","Train loss: 5.0871124267578125\n","Train loss: 4.495680809020996\n","Train loss: 4.404603004455566\n","Train loss: 5.016420364379883\n","Train loss: 4.321847438812256\n","Train loss: 4.89340877532959\n","Train loss: 4.328012466430664\n","Train loss: 5.597177505493164\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 16/16 [00:00<00:00, 72.87it/s]\n","100%|██████████| 16/16 [00:00<00:00, 412.79it/s]\n","100%|██████████| 16/16 [00:00<00:00, 362.26it/s]\n","100%|██████████| 16/16 [00:00<00:00, 476.48it/s]\n","100%|██████████| 16/16 [00:00<00:00, 478.75it/s]"],"name":"stderr"},{"output_type":"stream","text":["Train loss: 3.588991641998291\n","Train loss: 3.9179019927978516\n","Train loss: 4.84475564956665\n","Train loss: 4.809310436248779\n","Train loss: 3.8026514053344727\n","Train loss: 5.6193389892578125\n","Train loss: 3.7394587993621826\n","Train loss: 3.8403148651123047\n","##################################################\n","Epoch: 2\n","Train loss: 4.912628173828125\n","Train loss: 4.365656852722168\n","Train loss: 4.283516883850098\n","Train loss: 4.8920087814331055\n","Train loss: 4.200763702392578\n","Train loss: 4.617302894592285\n","Train loss: 4.142653942108154\n","Train loss: 5.453695297241211\n","Train loss: 3.476940393447876\n","Train loss: 3.7472763061523438\n","Train loss: 4.685545921325684\n","Train loss: 4.41632080078125\n","Train loss: 3.665771245956421\n","Train loss: 5.48996639251709\n","Train loss: 3.5916147232055664\n","Train loss: 3.7136001586914062\n","##################################################\n","Epoch: 3\n","Train loss: 4.7411346435546875\n","Train loss: 4.23769998550415\n","Train loss: 4.163978099822998\n","Train loss: 4.769026756286621\n","Train loss: 4.080937385559082\n","Train loss: 4.354514122009277\n","Train loss: 3.961369752883911\n","Train loss: 5.312581539154053\n","Train loss: 3.3717219829559326\n","Train loss: 3.582047462463379\n","Train loss: 4.536040782928467\n","Train loss: 4.050350189208984\n","Train loss: 3.5316872596740723\n","Train loss: 5.362956523895264\n","Train loss: 3.4465887546539307\n","Train loss: 3.5896668434143066\n","##################################################\n","Epoch: 4\n","Train loss: 4.572724342346191\n","Train loss: 4.111837387084961\n","Train loss: 4.0460124015808105\n","Train loss: 4.647488594055176\n","Train loss: 3.962454080581665\n","Train loss: 4.106075286865234\n","Train loss: 3.7842812538146973\n","Train loss: 5.173841953277588\n","Train loss: 3.2730350494384766\n","Train loss: 3.4228668212890625\n","Train loss: 4.396053314208984\n","Train loss: 3.7122113704681396\n","Train loss: 3.4004573822021484\n","Train loss: 5.238279342651367\n","Train loss: 3.3046202659606934\n","Train loss: 3.468519687652588\n","##################################################\n","Epoch: 5\n","Train loss: 4.40751838684082\n","Train loss: 3.98810076713562\n","Train loss: 3.9296436309814453\n","Train loss: 4.527414321899414\n","Train loss: 3.845386266708374\n","Train loss: 3.873420238494873\n","Train loss: 3.611532211303711\n","Train loss: 5.037493705749512\n","Train loss: 3.180506706237793\n","Train loss: 3.2703592777252197\n","Train loss: 4.2655792236328125\n","Train loss: 3.4036967754364014\n","Train loss: 3.2721424102783203\n","Train loss: 5.115907669067383\n","Train loss: 3.1659741401672363\n","Train loss: 3.3501744270324707\n","Finished.\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"FDahBf6IX4py"},"source":["다음으로 Skip-gram 모델 학습입니다."]},{"cell_type":"code","metadata":{"id":"jJxGEusqFV5r","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1613385577674,"user_tz":-540,"elapsed":2109,"user":{"displayName":"오진석","photoUrl":"","userId":"12229120938967938448"}},"outputId":"736f41ab-6e2a-444b-9693-73a1dc6af0f5"},"source":["skipgram.train()\r\n","skipgram = skipgram.to(device)\r\n","optim = torch.optim.SGD(skipgram.parameters(), lr=learning_rate)\r\n","loss_function = nn.CrossEntropyLoss()\r\n","\r\n","for e in range(1, num_epochs+1):\r\n","  print(\"#\" * 50)\r\n","  print(f\"Epoch: {e}\")\r\n","  for batch in tqdm(skipgram_loader):\r\n","    x, y = batch\r\n","    x, y = x.to(device), y.to(device) # (B, W), (B)\r\n","    output = skipgram(x)  # (B, V)\r\n","\r\n","    optim.zero_grad()\r\n","    loss = loss_function(output, y)\r\n","    loss.backward()\r\n","    optim.step()\r\n","\r\n","    print(f\"Train loss: {loss.item()}\")\r\n","\r\n","print(\"Finished.\")"],"execution_count":22,"outputs":[{"output_type":"stream","text":["100%|██████████| 64/64 [00:00<00:00, 488.49it/s]\n","  0%|          | 0/64 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["##################################################\n","Epoch: 1\n","Train loss: 3.879277229309082\n","Train loss: 4.311881065368652\n","Train loss: 4.338291168212891\n","Train loss: 4.409280776977539\n","Train loss: 3.8724794387817383\n","Train loss: 3.9257640838623047\n","Train loss: 4.668275356292725\n","Train loss: 4.58461856842041\n","Train loss: 4.281807899475098\n","Train loss: 4.214297771453857\n","Train loss: 4.253112316131592\n","Train loss: 4.216219425201416\n","Train loss: 4.251491546630859\n","Train loss: 3.7652699947357178\n","Train loss: 3.8199732303619385\n","Train loss: 4.509627342224121\n","Train loss: 4.243988990783691\n","Train loss: 4.0105156898498535\n","Train loss: 3.913928508758545\n","Train loss: 3.8982949256896973\n","Train loss: 4.303450107574463\n","Train loss: 4.4208478927612305\n","Train loss: 4.666552543640137\n","Train loss: 4.006771087646484\n","Train loss: 3.597928762435913\n","Train loss: 4.507756233215332\n","Train loss: 4.740218162536621\n","Train loss: 4.451238632202148\n","Train loss: 3.972871780395508\n","Train loss: 4.088748455047607\n","Train loss: 4.291412353515625\n","Train loss: 4.096545696258545\n","Train loss: 4.4824604988098145\n","Train loss: 3.6928794384002686\n","Train loss: 3.9382548332214355\n","Train loss: 4.270084381103516\n","Train loss: 4.56751012802124\n","Train loss: 3.9101860523223877\n","Train loss: 4.093627452850342\n","Train loss: 4.33756685256958\n","Train loss: 4.448960781097412\n","Train loss: 4.152766227722168\n","Train loss: 4.152502536773682\n","Train loss: 4.499680519104004\n","Train loss: 4.074418067932129\n","Train loss: 4.3067946434021\n","Train loss: 4.173751354217529\n","Train loss: 4.359045028686523\n","Train loss: 4.300625801086426\n","Train loss: 3.966935157775879\n","Train loss: 4.539854526519775\n","Train loss: 4.047607898712158\n","Train loss: 4.264840126037598\n","Train loss: 4.6597442626953125\n","Train loss: 4.499445915222168\n","Train loss: 3.972635507583618\n","Train loss: 4.093784332275391\n","Train loss: 4.164492607116699\n","Train loss: 4.073958396911621\n","Train loss: 3.8962128162384033\n","Train loss: 4.129011154174805\n","Train loss: 4.132916450500488\n","Train loss: 4.592292785644531\n","Train loss: 3.632547616958618\n","##################################################\n","Epoch: 2\n","Train loss: 3.853123903274536\n","Train loss: 4.262998580932617\n","Train loss: 4.308370590209961\n","Train loss: 4.346323013305664\n","Train loss: 3.84879732131958\n","Train loss: 3.89483904838562\n","Train loss: 4.624831199645996\n","Train loss: 4.545593738555908\n","Train loss: 4.246270179748535\n","Train loss: 4.186915874481201\n","Train loss: 4.231131553649902\n","Train loss: 4.181715965270996\n","Train loss: 4.228328704833984\n","Train loss: 3.736332416534424\n","Train loss: 3.7912685871124268\n","Train loss: 4.481837749481201\n","Train loss: 4.216789245605469\n","Train loss: 3.982461452484131\n","Train loss: 3.885857105255127\n","Train loss: 3.8685152530670166\n","Train loss: 4.191155433654785\n","Train loss: 4.330167770385742\n","Train loss: 4.605064392089844\n","Train loss: 3.978278636932373\n","Train loss: 3.565429210662842\n","Train loss: 4.443492889404297\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 64/64 [00:00<00:00, 432.61it/s]\n"," 70%|███████   | 45/64 [00:00<00:00, 448.80it/s]"],"name":"stderr"},{"output_type":"stream","text":["Train loss: 4.688884735107422\n","Train loss: 4.418670177459717\n","Train loss: 3.931244134902954\n","Train loss: 4.063446998596191\n","Train loss: 4.264033317565918\n","Train loss: 4.071428298950195\n","Train loss: 4.458360195159912\n","Train loss: 3.672696590423584\n","Train loss: 3.9069161415100098\n","Train loss: 4.234782695770264\n","Train loss: 4.500520706176758\n","Train loss: 3.8653693199157715\n","Train loss: 4.057750225067139\n","Train loss: 4.307658672332764\n","Train loss: 4.42566442489624\n","Train loss: 4.121435165405273\n","Train loss: 4.092445373535156\n","Train loss: 4.4557085037231445\n","Train loss: 3.958235263824463\n","Train loss: 4.194893836975098\n","Train loss: 4.084729194641113\n","Train loss: 4.297762870788574\n","Train loss: 4.272451877593994\n","Train loss: 3.9394729137420654\n","Train loss: 4.505410194396973\n","Train loss: 4.002418518066406\n","Train loss: 4.2336344718933105\n","Train loss: 4.626457214355469\n","Train loss: 4.467716217041016\n","Train loss: 3.943756580352783\n","Train loss: 4.034486770629883\n","Train loss: 4.134688377380371\n","Train loss: 4.0453386306762695\n","Train loss: 3.86273455619812\n","Train loss: 4.094552040100098\n","Train loss: 4.100727081298828\n","Train loss: 4.55570650100708\n","Train loss: 3.579822540283203\n","##################################################\n","Epoch: 3\n","Train loss: 3.8276844024658203\n","Train loss: 4.214350700378418\n","Train loss: 4.278594493865967\n","Train loss: 4.284218788146973\n","Train loss: 3.8252830505371094\n","Train loss: 3.864396572113037\n","Train loss: 4.581986427307129\n","Train loss: 4.50676155090332\n","Train loss: 4.210921764373779\n","Train loss: 4.159660339355469\n","Train loss: 4.209239959716797\n","Train loss: 4.147457122802734\n","Train loss: 4.205513954162598\n","Train loss: 3.707589864730835\n","Train loss: 3.76277232170105\n","Train loss: 4.454324722290039\n","Train loss: 4.1897172927856445\n","Train loss: 3.9545764923095703\n","Train loss: 3.858137607574463\n","Train loss: 3.8389484882354736\n","Train loss: 4.080204486846924\n","Train loss: 4.241097927093506\n","Train loss: 4.544186115264893\n","Train loss: 3.949949026107788\n","Train loss: 3.5334396362304688\n","Train loss: 4.380100727081299\n","Train loss: 4.637921333312988\n","Train loss: 4.386775493621826\n","Train loss: 3.8901286125183105\n","Train loss: 4.038426399230957\n","Train loss: 4.236813545227051\n","Train loss: 4.046419143676758\n","Train loss: 4.434329032897949\n","Train loss: 3.652784824371338\n","Train loss: 3.875849962234497\n","Train loss: 4.19969367980957\n","Train loss: 4.434530735015869\n","Train loss: 3.821866750717163\n","Train loss: 4.022485256195068\n","Train loss: 4.2780609130859375\n","Train loss: 4.402411460876465\n","Train loss: 4.090484619140625\n","Train loss: 4.03394889831543\n","Train loss: 4.411806106567383\n","Train loss: 3.844202995300293\n","Train loss: 4.084396839141846\n","Train loss: 3.9974913597106934\n","Train loss: 4.237123489379883\n","Train loss: 4.24440860748291\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 64/64 [00:00<00:00, 432.36it/s]\n","100%|██████████| 64/64 [00:00<00:00, 440.65it/s]\n","  0%|          | 0/64 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Train loss: 3.9123969078063965\n","Train loss: 4.471397876739502\n","Train loss: 3.9579200744628906\n","Train loss: 4.202617645263672\n","Train loss: 4.593818664550781\n","Train loss: 4.436117172241211\n","Train loss: 3.9150567054748535\n","Train loss: 3.9760942459106445\n","Train loss: 4.105401515960693\n","Train loss: 4.017023086547852\n","Train loss: 3.829515218734741\n","Train loss: 4.060315132141113\n","Train loss: 4.068869590759277\n","Train loss: 4.519894599914551\n","Train loss: 3.5279757976531982\n","##################################################\n","Epoch: 4\n","Train loss: 3.8029375076293945\n","Train loss: 4.165946006774902\n","Train loss: 4.248966217041016\n","Train loss: 4.223013877868652\n","Train loss: 3.8019351959228516\n","Train loss: 3.834437131881714\n","Train loss: 4.5397491455078125\n","Train loss: 4.468124866485596\n","Train loss: 4.175765037536621\n","Train loss: 4.132532119750977\n","Train loss: 4.187439441680908\n","Train loss: 4.113443374633789\n","Train loss: 4.183045387268066\n","Train loss: 3.679044485092163\n","Train loss: 3.7344894409179688\n","Train loss: 4.427087783813477\n","Train loss: 4.162775039672852\n","Train loss: 3.9268641471862793\n","Train loss: 3.8307700157165527\n","Train loss: 3.8095970153808594\n","Train loss: 3.9707155227661133\n","Train loss: 4.153769493103027\n","Train loss: 4.483935832977295\n","Train loss: 3.9217844009399414\n","Train loss: 3.5019702911376953\n","Train loss: 4.317626953125\n","Train loss: 4.587328910827637\n","Train loss: 4.355537414550781\n","Train loss: 3.8495402336120605\n","Train loss: 4.0136871337890625\n","Train loss: 4.209754467010498\n","Train loss: 4.021517753601074\n","Train loss: 4.410367012023926\n","Train loss: 3.633139133453369\n","Train loss: 3.8450582027435303\n","Train loss: 4.164825439453125\n","Train loss: 4.369625091552734\n","Train loss: 3.7797515392303467\n","Train loss: 3.9878344535827637\n","Train loss: 4.248773574829102\n","Train loss: 4.379193305969238\n","Train loss: 4.059911727905273\n","Train loss: 3.9771087169647217\n","Train loss: 4.367972373962402\n","Train loss: 3.73250675201416\n","Train loss: 3.975433826446533\n","Train loss: 3.912173271179199\n","Train loss: 4.177148818969727\n","Train loss: 4.216495513916016\n","Train loss: 3.8857061862945557\n","Train loss: 4.437821388244629\n","Train loss: 3.91412353515625\n","Train loss: 4.171792030334473\n","Train loss: 4.561814308166504\n","Train loss: 4.404651165008545\n","Train loss: 3.8865368366241455\n","Train loss: 3.918651819229126\n","Train loss: 4.076636791229248\n","Train loss: 3.9890127182006836\n","Train loss: 3.796558380126953\n","Train loss: 4.02630615234375\n","Train loss: 4.037346839904785\n","Train loss: 4.484840393066406\n","Train loss: 3.477034330368042\n","##################################################\n","Epoch: 5\n","Train loss: 3.778864860534668\n","Train loss: 4.117792129516602\n","Train loss: 4.219487190246582\n","Train loss: 4.162755012512207\n","Train loss: 3.7787535190582275\n","Train loss: 3.8049638271331787\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 64/64 [00:00<00:00, 431.94it/s]"],"name":"stderr"},{"output_type":"stream","text":["Train loss: 4.498126029968262\n","Train loss: 4.4296875\n","Train loss: 4.140804290771484\n","Train loss: 4.105533123016357\n","Train loss: 4.1657304763793945\n","Train loss: 4.079675674438477\n","Train loss: 4.160921096801758\n","Train loss: 3.6506989002227783\n","Train loss: 3.7064223289489746\n","Train loss: 4.400124549865723\n","Train loss: 4.1359639167785645\n","Train loss: 3.8993258476257324\n","Train loss: 3.803755044937134\n","Train loss: 3.780463695526123\n","Train loss: 3.8628249168395996\n","Train loss: 4.068326950073242\n","Train loss: 4.42433500289917\n","Train loss: 3.8937864303588867\n","Train loss: 3.471031665802002\n","Train loss: 4.2561187744140625\n","Train loss: 4.537114143371582\n","Train loss: 4.324939727783203\n","Train loss: 3.8094940185546875\n","Train loss: 3.989232063293457\n","Train loss: 4.182858467102051\n","Train loss: 3.996727466583252\n","Train loss: 4.386472702026367\n","Train loss: 3.6137571334838867\n","Train loss: 3.814541816711426\n","Train loss: 4.130185604095459\n","Train loss: 4.305899143218994\n","Train loss: 3.73909854888916\n","Train loss: 3.953801393508911\n","Train loss: 4.219796657562256\n","Train loss: 4.3560004234313965\n","Train loss: 4.029715538024902\n","Train loss: 3.9220261573791504\n","Train loss: 4.324206352233887\n","Train loss: 3.623342990875244\n","Train loss: 3.868152141571045\n","Train loss: 3.828918933868408\n","Train loss: 4.117860317230225\n","Train loss: 4.188713073730469\n","Train loss: 3.8594002723693848\n","Train loss: 4.40468168258667\n","Train loss: 3.8710384368896484\n","Train loss: 4.1411566734313965\n","Train loss: 4.530428409576416\n","Train loss: 4.373319625854492\n","Train loss: 3.858198404312134\n","Train loss: 3.8622052669525146\n","Train loss: 4.048399448394775\n","Train loss: 3.961308002471924\n","Train loss: 3.7638673782348633\n","Train loss: 3.99252986907959\n","Train loss: 4.006162166595459\n","Train loss: 4.450528144836426\n","Train loss: 3.427025318145752\n","Finished.\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"Pi0sbHV6dEOR"},"source":["### **테스트**"]},{"cell_type":"markdown","metadata":{"id":"WGarLWxXeJvz"},"source":["학습된 각 모델을 이용하여 test 단어들의 word embedding을 확인합니다."]},{"cell_type":"code","metadata":{"id":"4A1wrl-L_RjF","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1613385581888,"user_tz":-540,"elapsed":1256,"user":{"displayName":"오진석","photoUrl":"","userId":"12229120938967938448"}},"outputId":"dd3b49e2-c392-43ef-fdf5-c67e274896c8"},"source":["for word in test_words:\r\n","  input_id = torch.LongTensor([w2i[word]]).to(device)\r\n","  emb = cbow.embedding(input_id)\r\n","\r\n","  print(f\"Word: {word}\")\r\n","  print(emb.squeeze(0))"],"execution_count":23,"outputs":[{"output_type":"stream","text":["Word: 음식\n","tensor([-7.9042e-01, -7.0538e-01, -6.6976e-01,  8.6610e-01, -8.6829e-01,\n","         1.2286e+00,  4.8231e-01,  8.1646e-01, -1.9411e+00,  8.9980e-01,\n","        -1.7746e+00, -4.5992e-01, -1.3263e+00,  3.5081e-01,  1.5046e+00,\n","         8.1896e-01,  1.1918e-04, -5.0712e-01,  9.6802e-01,  2.5530e-01,\n","         8.3008e-01, -6.7137e-01, -8.4117e-01, -3.9905e-01, -8.0826e-01,\n","        -1.0100e+00, -1.4331e+00, -9.6992e-01, -2.0723e-01, -6.3269e-01,\n","        -8.3237e-01, -1.0523e+00,  9.5183e-01, -1.2437e+00,  2.6162e-01,\n","        -7.7515e-02,  9.3255e-01, -2.2127e-01, -4.1224e-01,  7.8853e-01,\n","         3.7518e-01, -2.2188e-01,  5.6199e-01,  2.7056e+00, -2.4016e-01,\n","         2.4015e-01,  1.5320e+00, -9.3272e-01,  4.3075e-01,  5.2494e-01,\n","        -2.5973e-01,  1.6622e+00,  1.6973e+00,  1.6079e-01, -6.5152e-02,\n","        -9.4314e-01, -6.1241e-01, -1.5328e-02, -3.0202e+00,  2.5711e-01,\n","        -3.6682e-01, -8.8679e-01, -3.9826e-01, -2.1968e-01,  4.7693e-02,\n","         7.9119e-01, -3.1150e-02,  5.4193e-02,  1.6591e-01,  6.8592e-01,\n","        -4.4148e-01,  3.5732e-01, -1.0915e-03, -3.2772e-01,  8.8155e-02,\n","         3.9020e-01, -1.1901e+00, -1.2741e+00,  1.9070e+00, -1.5414e+00,\n","         1.1407e+00, -7.7203e-01, -8.7732e-01, -3.1973e-01,  1.3087e+00,\n","        -3.3098e-01, -1.6355e+00,  1.0000e+00,  1.9053e-01, -1.0587e-01,\n","         1.3489e+00,  4.3321e-02,  1.0645e-01, -2.3135e-02,  1.6182e+00,\n","        -4.2853e-01,  1.8072e-01, -6.5660e-01,  3.2151e-01,  1.2371e+00,\n","         2.9312e+00,  2.1018e+00, -7.1192e-01,  6.7528e-01,  6.1299e-01,\n","        -6.8908e-01,  1.1551e-01, -7.4156e-01, -4.9372e-01, -1.5830e+00,\n","         1.6069e+00,  1.1152e-01,  2.6022e+00, -1.8644e+00, -3.2640e-01,\n","        -2.1017e-01,  8.9031e-01,  1.1361e+00, -9.3360e-01, -2.0047e+00,\n","         3.7378e-01,  1.6851e+00, -1.5147e+00, -9.9418e-01, -1.1767e+00,\n","         1.6593e+00, -1.4997e+00,  1.2777e+00,  7.2971e-01, -1.7127e+00,\n","        -8.1462e-01,  8.7084e-01,  7.4055e-01, -1.9905e+00,  1.1115e+00,\n","        -3.4765e-01, -8.4225e-01,  6.9247e-01,  5.5805e-01, -1.2446e+00,\n","         1.0526e+00, -2.0287e-01,  3.2001e-01, -2.1588e-01, -1.2653e+00,\n","         1.5751e+00, -6.0860e-01,  7.3708e-02, -1.4102e+00, -8.0604e-01,\n","        -3.9835e-02, -3.4486e-01,  1.2062e+00,  3.7092e-01, -7.0426e-01,\n","         1.6398e+00,  5.9709e-02, -9.1075e-01,  5.4196e-01, -2.0505e-02,\n","        -1.1262e+00,  9.5843e-01,  5.6021e-01, -4.3586e-01,  4.1705e-01,\n","        -7.7451e-01, -8.2921e-01, -5.7902e-01, -1.0746e-01, -9.4821e-01,\n","        -1.1840e+00, -6.7021e-01,  4.6916e-01,  7.1428e-01, -1.7744e-01,\n","        -3.2545e-01, -6.6352e-01,  1.3777e-01,  1.5488e+00, -1.3350e-01,\n","        -7.6332e-01,  5.8816e-02,  3.8526e-01,  2.0959e+00, -7.9073e-01,\n","         2.3232e+00, -1.7779e+00,  1.9782e+00, -5.9677e-01,  9.9081e-02,\n","         1.3143e+00, -6.1355e-02,  2.5143e-01,  7.0642e-01,  1.1745e-01,\n","         1.9527e+00,  1.6271e+00, -5.2238e-02,  5.5326e-01, -6.6465e-01,\n","        -4.6400e-03,  2.0069e+00,  1.1489e+00,  1.0043e+00, -1.6503e+00,\n","         5.1493e-01, -1.5375e+00,  1.1048e+00, -2.1995e+00,  1.7565e-01,\n","        -1.3190e+00, -1.2735e+00,  1.8788e+00, -1.3392e+00, -3.8948e-02,\n","         6.4171e-01, -1.1566e+00, -4.1279e-01,  7.8737e-01, -1.5731e+00,\n","        -1.2348e+00, -2.2432e-01,  9.1878e-01, -1.0427e+00, -8.8830e-01,\n","         9.0940e-02,  1.0627e+00,  6.1268e-02, -1.1522e-01,  6.4075e-01,\n","        -1.2588e+00,  2.2747e+00,  1.6082e+00, -1.4296e+00,  6.4780e-01,\n","         7.4498e-01,  8.4886e-01,  7.4069e-01,  4.2217e-01, -1.2303e+00,\n","        -1.2407e+00,  9.1194e-01,  3.6591e-01, -1.2572e+00,  4.6555e-01,\n","         6.1642e-01,  7.2235e-01,  1.4867e+00,  6.3383e-01, -6.3082e-01,\n","        -1.7713e+00, -7.6436e-01,  9.5969e-01,  1.3795e+00,  1.1050e+00,\n","         5.8542e-01], device='cuda:0', grad_fn=<SqueezeBackward1>)\n","Word: 맛\n","tensor([-1.7831,  1.2559, -0.3199,  0.4629,  1.4993,  0.1982,  0.8212, -0.0745,\n","         0.8812, -0.7212,  1.6082, -0.4624,  1.4812,  0.2010,  1.5545,  2.0727,\n","        -1.4443, -0.7648,  0.3369,  2.1697,  0.3418,  0.6478, -0.3190, -0.8376,\n","         0.5383, -0.9099, -0.2062,  0.6527, -2.6041,  0.5612,  0.2538, -0.1176,\n","         0.4804, -0.6354,  0.9806, -0.9489,  0.4921,  1.5364, -0.7442,  1.5477,\n","        -0.1341,  0.5435, -0.5144, -0.9382, -1.0609,  0.4185,  0.1272,  0.0071,\n","        -0.0639, -0.5077,  0.0096,  0.8716, -0.5660,  0.2350, -0.0785, -0.6289,\n","        -0.0319,  1.2346,  0.1939,  0.9696, -0.0066, -1.5078, -0.4657,  1.9552,\n","         1.2038, -0.4785,  0.3835, -0.7726,  1.7253,  0.6422,  2.4360,  0.5496,\n","         0.8945,  1.2251,  2.2086,  0.5116,  1.7635, -0.3040, -1.1279,  0.5231,\n","        -0.2138,  0.1289,  0.0203, -0.4764, -0.3412, -0.1246, -0.8508,  0.4050,\n","         1.0847,  0.9658,  0.4432, -0.1190, -1.7857,  0.3075, -0.2695,  1.2408,\n","         0.6945, -0.1695,  2.4102,  0.0597,  0.3052, -0.0581, -0.2892, -0.8960,\n","        -1.2034, -0.3551, -0.2167,  1.4873, -0.2493,  1.0331,  1.4992, -0.0517,\n","        -0.7829, -0.4585, -0.6658,  0.3912, -0.1182,  0.7075, -0.2138, -0.6365,\n","         0.9078, -0.5630, -1.8199,  0.8682, -0.5828, -1.0434, -0.3582,  0.1882,\n","        -0.2163, -0.4218, -0.7900,  0.0794,  1.3714,  1.1274, -0.9219, -0.4632,\n","         1.0338,  1.4309,  1.4989, -1.7056, -0.1238, -0.2935,  1.1277,  1.4272,\n","        -0.5210,  0.3275, -2.0700,  1.5410,  0.3317,  0.2589,  0.4529, -0.2392,\n","         0.1060,  2.0713, -0.3943, -0.0700,  0.7136,  0.6796, -0.0042,  0.1053,\n","        -1.3361, -2.1731,  0.3256,  0.2032,  0.8328, -2.7693, -1.0707, -0.3591,\n","        -0.3780, -0.8185, -0.5162,  0.9590,  1.5263, -0.1658, -0.7700, -0.4912,\n","         0.2442,  3.0770,  1.1789,  2.0236,  0.7159,  0.9161,  0.0529, -0.6501,\n","        -0.7090,  0.3971, -0.3556,  1.7382,  1.2342, -0.4655, -0.6372,  0.0369,\n","         0.3036,  0.5866, -0.7163,  1.2170,  0.8505, -1.0237,  0.1473,  1.5699,\n","        -0.9381,  0.8807, -1.0991,  0.0972, -1.4322,  1.6843,  1.2371, -1.6725,\n","         0.4581,  0.0918, -0.2206, -0.7181,  0.3675, -0.0235, -1.2585,  0.1342,\n","         0.7808, -0.2954, -0.7033, -1.0014, -0.9550,  0.3097, -1.2275, -1.5899,\n","        -2.7372,  1.2121, -0.4870, -0.9176, -1.6769, -0.8216, -0.6823,  1.0375,\n","        -1.2407,  0.1298,  1.5071, -0.0604, -1.2017, -0.1060, -1.2287, -1.1248,\n","        -1.4275, -0.5827,  0.4331,  0.0433, -0.0844, -0.1106, -1.0378, -0.0506,\n","         1.2656, -0.5771, -0.1245, -0.8726,  0.3118,  0.1812,  0.7804,  1.7560],\n","       device='cuda:0', grad_fn=<SqueezeBackward1>)\n","Word: 서비스\n","tensor([-2.7830e-01,  2.0160e+00,  7.2958e-01,  1.9467e+00, -3.3423e-01,\n","         1.6768e-01, -8.9021e-02, -6.0674e-01,  1.0753e+00,  9.4273e-01,\n","         8.6911e-01,  2.6074e-03, -1.0805e+00, -1.1750e+00, -1.2742e+00,\n","        -9.7684e-01,  8.1764e-01, -6.4079e-01, -4.8581e-01, -1.5784e-01,\n","        -1.7472e-01, -2.3364e-01, -1.3016e+00, -7.1666e-01, -2.3557e-01,\n","         1.8485e+00,  5.9593e-01,  1.4343e+00,  2.3427e-01, -2.2601e+00,\n","         5.7079e-01,  4.3450e-01,  1.7985e-01,  4.2371e-01, -6.1103e-01,\n","         1.0133e-01,  1.8851e-01,  6.0473e-01,  9.4508e-01, -4.0436e-01,\n","        -3.6562e-01,  1.3656e+00,  5.0570e-01,  3.7260e-01,  2.8776e-01,\n","        -3.3251e-01, -6.2194e-01,  8.2427e-01,  1.2773e+00, -6.3117e-01,\n","         1.1140e+00, -4.3032e-01, -1.3174e+00, -2.9664e-01, -3.5136e-01,\n","        -7.7609e-01, -5.7896e-01, -2.3897e-01,  6.1492e-01, -3.9338e-01,\n","         1.9408e+00,  5.8044e-01,  5.2101e-01, -7.4403e-01, -1.5288e+00,\n","         1.1188e+00,  2.3401e-02, -8.3901e-01,  4.4195e-01,  3.0764e-01,\n","         1.3939e+00, -1.8979e-01, -6.2000e-01,  3.5218e-01, -2.7195e-01,\n","        -1.0813e+00, -7.1003e-01,  5.4876e-01,  4.5176e-01,  6.5181e-01,\n","         9.6072e-01,  9.9738e-01, -3.8652e-01, -2.3534e+00,  5.7319e-01,\n","        -1.4191e+00, -5.2617e-01, -1.2941e+00,  9.0299e-01,  9.6063e-02,\n","        -5.3294e-01,  1.0945e+00,  6.9000e-01,  1.1895e+00, -4.6462e-01,\n","         4.7180e-01,  1.7116e+00,  4.1471e-01,  1.5190e+00,  1.8259e+00,\n","        -1.3043e+00, -1.6085e+00,  2.8321e+00, -4.0023e-01,  1.3608e+00,\n","         6.5526e-01, -5.6257e-01, -1.0899e+00,  3.4731e-01, -2.3229e+00,\n","        -6.8338e-01, -2.5373e-01, -2.6508e-01, -1.1286e+00, -1.2976e-01,\n","        -7.2391e-01,  1.2022e+00, -2.5498e-01,  5.8884e-01, -6.3519e-01,\n","        -8.8242e-01, -2.0120e+00,  1.3972e+00, -5.8876e-01, -3.9205e-01,\n","        -1.4378e+00, -2.6354e-02,  5.9136e-01, -9.7929e-01, -2.5657e-01,\n","         3.4273e-01,  4.7828e-01, -4.4077e-01,  1.0332e+00, -8.2972e-01,\n","         1.8020e-02, -4.5441e-01,  2.3362e+00, -3.0051e-01, -4.8253e-01,\n","        -3.2032e-01, -5.5699e-01,  8.1382e-02, -1.2936e+00,  2.6499e-01,\n","         1.0467e+00, -1.5578e+00,  6.8563e-02,  1.3820e+00,  1.3288e+00,\n","        -1.1343e+00,  4.8319e-01,  1.1563e+00,  3.8508e-01,  6.9215e-01,\n","        -6.7672e-01,  8.0849e-01,  2.1686e+00,  2.4525e-01, -1.6636e+00,\n","        -2.5762e-01,  9.6748e-01, -8.3092e-01, -5.4408e-01,  1.1769e+00,\n","         2.1791e-01, -5.5420e-01, -1.3531e+00, -3.9239e-01,  1.7688e+00,\n","         1.6428e+00, -5.1968e-01,  5.8039e-01,  4.0417e-01,  1.0904e-01,\n","        -1.6862e-02,  2.3320e-01, -4.6589e-01,  4.0592e-01, -5.6715e-02,\n","         3.5315e-01,  4.9590e-01,  4.2818e-01, -7.6692e-01,  4.8171e-01,\n","        -7.8420e-01, -7.8075e-01, -6.3479e-01, -2.9706e-01,  2.4811e-01,\n","        -1.1984e-01, -7.8411e-01, -6.6247e-01, -1.1263e+00, -2.8414e-01,\n","        -4.1939e-01, -2.5191e-01, -5.6535e-02,  1.2977e-01, -1.4596e+00,\n","         9.3316e-01, -1.0640e+00,  8.7722e-01, -4.9306e-01, -1.9222e+00,\n","        -9.9710e-01,  1.1134e+00, -8.2985e-01,  6.0619e-02, -4.9462e-02,\n","        -2.8601e-01,  5.6268e-01, -1.1710e+00, -1.5871e+00,  5.8543e-01,\n","        -3.2090e-01, -3.4841e-01, -1.3539e+00,  2.1455e-01, -2.0961e+00,\n","        -4.7519e-02, -1.3185e+00, -1.3551e+00, -3.5197e-01,  1.0484e+00,\n","        -1.2278e+00, -1.1657e+00, -9.0664e-01,  2.6819e-01,  1.4974e+00,\n","         6.3942e-01,  8.6046e-01,  7.1413e-03, -1.1738e+00,  4.0280e-01,\n","         7.0962e-01,  2.6881e-01,  5.1941e-01,  1.8307e-02, -2.8969e-01,\n","         4.2089e-02, -5.2605e-01,  1.5866e+00, -2.6302e-01, -6.8111e-01,\n","        -4.4358e-01, -2.0692e-01,  1.4955e-02,  3.6491e-01,  1.0610e+00,\n","        -1.2745e-01,  1.4071e+00, -1.2537e+00, -2.6403e-01, -8.8653e-01,\n","         5.2528e-01], device='cuda:0', grad_fn=<SqueezeBackward1>)\n","Word: 위생\n","tensor([ 0.9812,  0.3069, -0.6086,  0.1091,  0.5547,  1.0017, -0.6902, -1.7170,\n","         2.1826, -0.1060, -1.5593, -1.2935,  0.9967, -0.5356,  2.9272,  0.3805,\n","        -0.2618,  0.4194, -0.4190, -1.5845,  1.4498, -1.7274,  0.3767,  0.3722,\n","         1.7155, -0.5405, -0.2086,  0.4660,  1.1938,  0.8944, -0.1819,  1.8012,\n","         0.3858,  0.1313, -0.4142, -0.5897, -1.0017,  0.5703, -0.2761,  0.5481,\n","         0.7850,  1.8488,  1.3787,  2.5033,  0.5915,  0.4771, -0.1165, -0.7949,\n","         0.7838, -1.0538,  0.3196, -0.2745,  0.9707, -0.0392, -0.6867,  3.3977,\n","        -1.1061, -0.8403, -1.0270,  0.6355,  0.0497,  0.6368,  2.2388, -1.5145,\n","         1.0269,  0.5439, -1.3982, -0.6276, -0.5194,  0.7337,  0.1354, -0.0797,\n","         0.4877, -0.7774,  1.3260,  1.2693,  0.0895, -0.1372,  0.0607,  0.7901,\n","        -1.0322, -1.2529, -1.0174, -1.3008,  1.5785,  0.4769, -0.0964,  0.5708,\n","        -0.4696,  0.8751,  1.0191,  0.5987, -0.4420,  0.2081, -1.2275, -1.0854,\n","         0.9046,  1.5621,  0.1595, -0.5398,  0.3447, -0.5165, -0.5849,  0.2102,\n","        -1.0264,  0.0711, -0.6292, -0.5249, -0.2396, -1.6342,  2.4066,  0.9893,\n","         0.0261, -0.4519,  0.7087, -0.1199, -0.1887, -1.6927,  0.9942, -1.3729,\n","        -2.0838, -1.3181,  0.7435, -0.5345, -0.2205,  1.0311, -0.9418, -0.1592,\n","        -0.5069, -1.0717,  1.2717, -1.4741, -0.8223, -1.0134,  1.8127,  1.2102,\n","         0.6175,  0.0662,  2.4000,  2.1921, -0.5581, -0.6439, -0.2844,  0.3452,\n","         0.8814,  1.2084,  0.3498, -0.6210, -0.8422, -0.7729, -0.1475, -1.1046,\n","         1.3319,  0.8594,  0.8766,  1.6125,  1.1388, -0.2473,  0.0946,  1.2586,\n","         2.1687,  0.9330,  1.3552, -0.0343,  1.5431, -0.2159, -0.6438, -0.9959,\n","         0.2882,  1.6022,  0.4503, -1.3258,  1.0815, -0.0786,  1.1129,  0.4512,\n","        -1.4125,  1.1105,  1.5589, -1.4952, -0.2855, -2.2271,  0.6048,  0.0976,\n","        -1.5715, -0.5224,  0.9824, -0.0922, -0.6653,  0.1066,  0.7470, -0.7182,\n","        -1.7682, -0.7625,  1.1899,  0.1177,  0.5598, -0.4160,  0.7342,  1.1852,\n","        -1.2451, -0.9766,  0.7687,  1.0093, -1.3010, -1.4617,  0.3043,  0.6150,\n","        -1.0053, -0.4617,  0.2848,  1.3092,  0.2207,  1.5142, -0.8105,  0.2386,\n","        -1.7984,  0.6118,  0.5149, -1.6040,  0.7225, -0.4167, -0.6111, -0.8842,\n","        -0.0165,  0.5791, -0.6226, -0.6524, -0.5638, -1.0815, -1.4823,  0.0870,\n","        -0.5966,  0.0691,  0.0430, -2.1660,  2.4834,  0.2932, -1.3866, -0.7564,\n","         0.8477, -0.9821,  0.5761,  1.1232,  1.2582,  0.8645, -0.4864,  0.1547,\n","        -0.7635, -0.3901, -0.8797,  0.3025, -0.6007, -1.0408,  0.7923, -0.8132],\n","       device='cuda:0', grad_fn=<SqueezeBackward1>)\n","Word: 가격\n","tensor([ 6.9625e-01, -1.1147e+00,  4.4056e-01,  6.9358e-01, -9.7317e-01,\n","        -1.0201e+00,  2.2571e+00, -2.8291e-01,  9.9417e-01,  2.3088e+00,\n","        -7.6680e-01,  6.2311e-01, -1.0255e+00, -9.7710e-01, -1.2532e-01,\n","        -2.0351e-01, -2.3112e-01,  4.2085e-01, -5.0385e-02,  7.4475e-01,\n","        -2.6970e-01,  3.0110e-01, -2.0105e+00,  6.0745e-01,  1.7393e-01,\n","         1.8749e-01,  8.9333e-01,  1.1083e+00,  4.5174e-02, -1.2526e+00,\n","         1.0396e+00, -6.7093e-01,  5.0356e-01,  1.6527e+00,  1.9140e+00,\n","        -3.1888e-01,  8.2601e-01,  7.0854e-01, -1.7393e+00,  9.7649e-02,\n","        -3.3197e-01,  3.5748e-01,  5.2811e-01,  1.3043e-01,  1.5852e+00,\n","         3.0940e-01,  5.7813e-01,  3.9049e-01,  3.2863e-01, -9.6064e-01,\n","         2.3342e+00,  6.6276e-01,  1.4747e+00, -1.0555e+00,  9.9539e-01,\n","         1.2865e+00, -4.1838e-01,  2.1833e-01,  2.1515e-01,  2.1929e-01,\n","         1.7584e+00, -4.0403e-01, -1.4313e+00,  2.0359e+00, -6.9232e-01,\n","         1.1078e+00, -2.3165e-01, -1.0649e-01,  1.3682e+00, -2.6779e-02,\n","         1.3755e-02, -7.7320e-01,  2.7131e+00,  1.8878e-02,  4.8535e-01,\n","        -3.5887e-01, -8.8453e-01, -5.4366e-01,  3.3293e-01,  4.2950e-01,\n","         1.2219e+00,  2.9329e-01,  1.0546e+00,  8.1318e-01, -1.2419e-01,\n","         2.2074e-01, -8.3377e-01, -1.5410e+00,  7.0891e-01,  7.3511e-02,\n","         2.8000e-02, -1.6291e-01,  1.5204e-01,  1.0997e+00,  1.2053e+00,\n","         1.4304e-01,  1.0289e+00, -4.8800e-02,  1.3379e+00,  2.5341e-01,\n","         1.3900e+00, -5.2830e-02,  5.4356e-01,  3.7913e-01,  1.5958e+00,\n","        -3.2291e+00,  1.3628e+00,  6.4583e-01,  8.5539e-01, -1.1235e+00,\n","        -6.3321e-01, -1.0878e-01,  2.3212e-01, -1.2348e+00, -2.3267e-01,\n","         5.8155e-02,  1.5444e+00, -1.3687e+00,  1.1865e-01,  1.3078e+00,\n","        -1.2725e-01,  3.2138e-01, -1.1506e-01,  2.1513e+00,  9.6876e-01,\n","         1.8860e+00,  8.0820e-01, -6.2958e-01,  1.7648e+00,  1.1589e+00,\n","         1.7027e+00,  2.7176e-03,  8.7118e-01,  1.4368e+00, -1.4204e+00,\n","         1.4939e+00,  1.0751e-03,  2.7181e-01, -2.0357e+00,  1.1355e-01,\n","         6.1217e-02, -1.0244e+00, -6.9560e-01, -3.9037e-01,  5.3766e-01,\n","         7.9177e-01, -8.4564e-01,  1.1060e+00,  8.3761e-01, -6.9049e-01,\n","        -1.5649e+00, -1.9217e-01, -1.1894e+00, -6.3265e-01,  6.4256e-01,\n","         1.0366e-01,  1.3470e+00,  2.2724e-01,  2.2723e-01,  6.4153e-01,\n","        -2.7291e-01, -1.5512e-01,  1.0468e+00, -7.0939e-01,  1.1610e+00,\n","        -1.2056e+00,  5.0965e-01,  1.0011e+00,  9.8247e-01,  1.7869e+00,\n","        -1.3879e-01, -3.2753e-01, -1.9663e-01,  7.0377e-01,  6.2839e-01,\n","         3.9846e-02, -6.5997e-01, -6.0944e-01,  2.7993e+00,  2.1768e-01,\n","        -4.2506e-01, -2.1810e-01,  2.3831e-01,  1.0906e+00,  9.2962e-01,\n","        -1.4337e+00,  1.7863e+00,  1.1941e+00,  2.2513e-01, -2.5141e-01,\n","         1.0347e+00,  4.4061e-01,  8.4744e-01,  1.3689e+00, -1.9119e+00,\n","        -1.7135e+00, -4.8509e-01,  1.2304e+00, -1.0779e+00,  1.5088e-01,\n","         8.3017e-01, -7.3482e-01,  6.1905e-02,  6.4038e-01, -1.5931e+00,\n","        -9.6860e-01,  3.3061e-01, -1.6558e+00,  1.1642e+00, -3.2768e-01,\n","        -1.7799e-01,  4.3779e-01,  6.1706e-01,  1.0160e+00,  1.4087e-02,\n","         6.9517e-01,  9.0546e-01,  3.4383e-01, -4.8637e-01, -7.0298e-01,\n","         1.5023e+00, -3.2908e-01, -9.6100e-01, -6.3157e-01,  2.0145e-01,\n","        -5.0026e-01,  2.4499e-01, -2.3813e-01,  3.5958e-01,  2.8033e-01,\n","         1.3756e+00,  6.0745e-01, -2.5244e+00, -1.6726e+00,  4.9090e-02,\n","         9.2893e-02,  6.6493e-01,  2.9762e-01,  3.0828e-01,  1.6895e+00,\n","         1.1198e+00, -1.4725e+00, -4.0676e-01, -5.9750e-01,  1.0304e+00,\n","         2.0672e+00, -1.4236e+00,  2.9224e-01,  9.3279e-01, -1.0392e+00,\n","        -2.4386e-01, -6.9186e-01,  3.7658e-01,  6.0891e-01, -3.6293e-01,\n","         6.1030e-01], device='cuda:0', grad_fn=<SqueezeBackward1>)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"_l5cPRZZe-R4","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1613385587130,"user_tz":-540,"elapsed":1675,"user":{"displayName":"오진석","photoUrl":"","userId":"12229120938967938448"}},"outputId":"27965d01-c54c-4b6b-abbd-e2936bfa303b"},"source":["for word in test_words:\r\n","  input_id = torch.LongTensor([w2i[word]]).to(device)\r\n","  emb = skipgram.embedding(input_id)\r\n","\r\n","  print(f\"Word: {word}\")\r\n","  print(max(emb.squeeze(0)))"],"execution_count":24,"outputs":[{"output_type":"stream","text":["Word: 음식\n","tensor(3.6042, device='cuda:0', grad_fn=<UnbindBackward>)\n","Word: 맛\n","tensor(2.5437, device='cuda:0', grad_fn=<UnbindBackward>)\n","Word: 서비스\n","tensor(3.2040, device='cuda:0', grad_fn=<UnbindBackward>)\n","Word: 위생\n","tensor(2.8895, device='cuda:0', grad_fn=<UnbindBackward>)\n","Word: 가격\n","tensor(2.2909, device='cuda:0', grad_fn=<UnbindBackward>)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"PmN4IchwisOO"},"source":["!apt-get install -qq texlive texlive-xetex texlive-latex-extra pandoc\r\n","!pip install -qq pypandoc\r\n","\r\n","from google.colab import drive\r\n","drive.mount('/content/drive')\r\n","\r\n","!jupyter nbconvert --to PDF '/content/drive/My Drive/Colab Notebooks/1_naive_bayes.ipynb의 사본'"],"execution_count":null,"outputs":[]}]}